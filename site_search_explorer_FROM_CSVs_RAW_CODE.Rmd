---
title: "Site Search Analysis & Word Clouds"
output:
  html_document: default
  theme: cerulean
  highlight: pygments
  pdf_document: default
  
---
## General Notes

This code was adapted from code that **[Tim Wilson](https://www.https://www.searchdiscovery.com/blog/tim-wilson-100/)** shared at the 2018 Adobe Summit.  

More of Tim's work can be found at: <https://rpubs.com/tgwilson>.

## Setup

Load and install the required packages for word cloud creation

```{r setup, message=FALSE}
# Load libraries.
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse,       # For manipulating the data
               tidytext,        # For manipulating text data, specifically
               DT,              # To give us interactivity in the tables
               tm,              # For removing stopwords
               SnowballC,       # For stemming / text mining
               wordcloud)       # For making a pie chart (not really)
```

## Upload data from a .CSV file

Your data file must be a .csv with two columns: 1) raw search terms and 2) raw search term frequency

The following chunk of code opens a file browser and displays the first 20 rows of the .csv selected.

```{r Source_agnostic, message=FALSE}

# Opens file browser

site_searches <- read.csv(file.choose())

head(site_searches, 20)
```

## Clean up your raw data

Clean up the data a bit by renaming columns and replacing erroneous characters that may be present.  Modification may be necessary here depending on what errant characters show up in your data.

```{r data_cleanup, message=FALSE}

# Rename the two columns
names(site_searches) <- c("search_term","metric")

# Replaces all instances of '+' with a space.  '\\' had to be added because gsub treats '+' as a special character.
# See: https://stat.ethz.ch/pipermail/r-help/2001-August/014356.html
site_searches$search_term <- gsub("\\+", " ", site_searches$search_term)

# Check out the results to make sure they look right
head(site_searches, 20)

```

## Get the List of Questions Asked in Search

**Note: this is helpful for overall analysis, but this section may be skipped if you're only looking to generate a word cloud**

The following search phrases started with a "question" word: who, what, why, when, where, or how. While these are typically low-frequency searches, they represent the voice of the customer with a high degree of specificity.*

```{r search_questions, message=FALSE}

# Subset the data to get the questions
site_search_questions <- site_searches %>% 
  filter(grepl("^(who|what|why|when|where|how)\\ ", search_term))

# Display the questions
datatable(site_search_questions,
          rownames = FALSE,
          options = list(columnDefs = list(list(className = 'dt-left', targets = 0))))

```

_* This filtering of site searches was something [Nancy Koons](https://www.linkedin.com/in/nkoons/) presented at Adobe Summit as part of Analytics Idol some years ago. Just because it's an oldie doesn't mean it isn't a goodie!_

## Create a Word Cloud with the Raw Data

Let's start with a word cloud without _any_ additional cleanup of the data.

```{r word_cloud_raw, message=FALSE}

# Set a seed so the same word cloud will be generated every time with the same data.
set.seed(1120)

# Set the color palette to use
palette <- rev(brewer.pal(8,"Spectral")) 

# Generate the word cloud
wordcloud(site_searches$search_term,
          freq = site_searches$metric,  # The 'frequency' (volume) of the term's usage
          scale=c(4,0.5),               # Max/min size of words
          max.words = 500,              # Max # of search terms to include in the wordcloud
          min.freq = 3,                 # Cutoff for # of searches to include a term
          random.order = FALSE,
          rot.per = 0,                  # % of words to rotate 90 degrees
          colors = palette)

```

## Build and Output a (Better) Word Cloud

This is the word cloud with stemming, removal of stopwords, and the removal of selected words that are not of interest.*

Remove specific words or characters by adding them manually to the exclusion_terms list.

*Many of the following lines of code can be edited or commented-out entirely by placing a "#" in front to modify the final word cloud.  Stemming has been commented out in this example.

```{r word_cloud, message=FALSE}

# Enter words to exclude from the word cloud. These will be applied *after*
# stemming, so keep that in mind
exclusion_terms <- c("h", "mnjhgsfd", "b", "d8", "d9", "a4", "e0", "a7", "27", "a8", "4325", "19", "e", "d", "v", "f", "t", "m", "P", "p")

# Make a copy of the site search data frame for munging for the wordcloud
wordcloud_df <- site_searches

# Convert UTF-8 to ASCII (needed because tm doesn't seem to like UTF-8 accented characters)
wordcloud_df$search_term <- iconv(wordcloud_df$search_term, "UTF-8", "ASCII") 

# Split out phrases to be individual words (and convert to lowercase)
# "dogs and cats" | 3
# "kittens"       | 2
# Becomes:
# "dogs"          | 3
# "and"           | 3
# "cats"          | 3
# "kittens"       | 2
wordcloud_df <- unnest_tokens(wordcloud_df, 
                     output = search_term, 
                     input = search_term)

# Remove stopwords: a, the, as, etc. 
wordcloud_df <- wordcloud_df %>%
  filter(!search_term %in% stopwords(kind = "en"))
  
# Perform stemming (e.g., "computer" and "computers" and "compute" all  become "comput")
# wordcloud_df <- wordcloud_df %>%
# mutate(search_term = wordStem(search_term))

# Pull out the exclusion terms
wordcloud_df <- wordcloud_df %>% 
  filter(!search_term %in% exclusion_terms)

# Collapse the table. This will combine terms after stemming
wordcloud_df <- wordcloud_df %>%
  group_by(search_term) %>% 
  summarise(metric = sum(metric)) %>% 
  arrange(-metric)

# Generate the word cloud
wordcloud(wordcloud_df$search_term,wordcloud_df$metric, 
          scale=c(5,0.7),      # Max/min size of words
          max.words = 500,       # Max # of search terms to include in the wordcloud
          min.freq = 5,          # Cutoff for # of searches to include a term
          random.order = FALSE,
          rot.per = 0,           # % of words to rotate 90 degrees
          colors = palette)

```


The following terms have been removed for clarity: `r paste(exclusion_terms, collapse=", ")`.